# Multi armed bandits

Based on the book "Bandit Algorithms for Website Optimization", John Myles White

## Algorithms
- EpsilonGreedy
- Exp3
- Hedge
- Softmax
- USB

## Arms
- Bernoulli
- Normal
- Adversarial

## Testing Framework